%\VignetteIndexEntry{SimDesign}
%\VignetteEngine{knitr::knitr}
---
title: "Compromise analysis"
author: "Phil Chalmers"
output:
  html_document:
    number_sections: yes
    toc: yes
    code_download: true
---

```{r include=FALSE}
options(digits = 3)
```

# Compromised power analysis

In compromised power analyses, $\alpha$ and $1-\beta$ are computed as functions of the effect size, sample size, model, and most importantly the error probability ratio $q=\frac{\beta}{\alpha}$ to indicate a type of trade-off between Type I and II errors. Setting $\alpha=\beta=1$ indicates an equal trade-off between Type I and Type II errors, while a $q=4$ indicates that Type II errors are four-times as costly to make than a Type I error. This is particularly useful when the sample size required from prior power analysis suggest a much larger size than a researcher can afford.

For instance, suppose that only $N=100$ per group are possible for an independent samples $t$-test analysis with a Welch correction, and the true effect size is thought to be $d=.3$. In such a simulation, and assuming for the moment that $\alpha=.05$ (will be changed momentarily thanks to the `store_results = TRUE` flag), then the following indicates the $q=\frac{\beta}{\alpha}$ error ratio estimate for this fixed $\alpha$ level. 



```{r}
library(SimDesign)

Design <- createDesign(N = 100,
                       d = .3, 
                       alpha = .05)
Design    

# print RStudio special disabling flags (fixes missing variables when Attach used)
Attach(Design, RStudio_flags = TRUE)

# !diagnostics suppress=N,d,alpha

#~~~~~~~~~~~~~~~~~~~~~~~~
#### Step 2 --- Define generate, analyse, and summarise functions

Generate <- function(condition, fixed_objects = NULL) {
    Attach(condition)
    group1 <- rnorm(N)
    group2 <- rnorm(N, mean=d)
    dat <- data.frame(DV = c(group1, group2),
                      group = rep(c('G1', 'G2'), each=N))
    dat
}

Analyse <- function(condition, dat, fixed_objects = NULL) {
    p <- t.test(DV ~ group, data=dat)$p.value
    p
}

Summarise <- function(condition, results, fixed_objects = NULL) {
    rate <- EDR(results, alpha=condition$alpha, unname = TRUE)
    ret <- c(q = (1-rate) / condition$alpha)
    ret
}

#~~~~~~~~~~~~~~~~~~~~~~~~
#### Step 3 --- Optimize N over the rows in design

sim <- runSimulation(design=Design, replications=100000, 
                     generate=Generate, analyse=Analyse,
                     summarise=Summarise, store_results=TRUE)
sim
```


However, because `store_results=TRUE` is used the results can be `reSummarise()`ed using a different $\alpha$ cut-off, where it is possible to obtain some target $q$ given the stored stimulation results. For example,

```{r}
# compute beta/alpha ratio given different alpha
compromise <- function(alpha, sim, Design){
    Design$alpha <- alpha
    out <- reSummarise(Summarise, results=sim, Design=Design)    
    out$q
}

compromise(.3, sim=sim, Design=Design)
compromise(.01, sim=sim, Design=Design)
```
which indicates different $q$ ratios. If a specific ratio is desired, then this amounts to performing some root-solving until the target $f(\alpha) = q$ is obtained.

```{r}
# define root function f(alpha) - q = 0
compromise_root <- function(alpha, target.q, ...)
    compromise(alpha, ...) - target.q

# solve alpha given equal beta/alpha trade-off  
root1 <- uniroot(compromise_root, c(.01, .3), target.q=1, 
        sim=sim, Design=Design)
root1

# solve alpha beta/alpha trade-off 4 times worse (beta = 4 * alpha)
root4 <- uniroot(compromise_root, c(.01, .3), target.q=4, 
        sim=sim, Design=Design)
root4
```
Hence, when equal $\beta$ and $\alpha$ errors are desirable then the $\alpha$ to utilize is `r round(root1$root, 3)`, while if the Type I errors are 4 times more costly than the Type II errors then $\alpha$ should be selected to be approximately `r round(root4$root, 3)`.


# Compromise analysis with empirical $\alpha$ estimate

In situations where the Type I error rate controlled by a select $\alpha$ is known or suspected to be sub-optimal (e.g., small samples that utilize maximum-likelihood estimators), it is possible to define the compromise ratio $q = \frac{\beta}{\alpha}$ in terms of the empirical Type I error rate rather than the assumed nominal $\alpha$. To do so requires more computation as the null model must also be generated and analysed as well, however the resulting compromise ratio and root-solved cut-offs should perform more honestly in practice. Below is an example of utilizing the empirical Type I error estimate rather than the assume Type I error = $\alpha$.

```{r}

#####################
# Same as above, however if Type I error not nominal then may wish to use 
# empirical Type I error estimate instead
library(SimDesign)

Design <- createDesign(N = 100,
                       d = .3, 
                       alpha = .05)
Design    # solve for NA's

#~~~~~~~~~~~~~~~~~~~~~~~~
#### Step 2 --- Define generate, analyse, and summarise functions

Generate <- function(condition, fixed_objects = NULL) {
    Attach(condition)
    group1 <- rnorm(N)
    group2 <- rnorm(N, mean=d)
    group3 <- rnorm(N)   # For H0 tests
    dat <- data.frame(DV = c(group1, group2),
                      DV.null = c(group1, group3),
                      group = rep(c('G1', 'G2'), each=N))
    dat
}

Analyse <- function(condition, dat, fixed_objects = NULL) {
    p.power <- t.test(DV ~ group, data=dat)$p.value    # (1-beta)
    p.null <- t.test(DV.null ~ group, data=dat)$p.value   # alpha
    nc(p.null, p.power)
}

Summarise <- function(condition, results, fixed_objects = NULL) {
    rate <- EDR(results, alpha=condition$alpha)
    ret <- c(q = unname((1-rate["p.power"]) / rate["p.null"]))
    ret
}

#~~~~~~~~~~~~~~~~~~~~~~~~
#### Step 3 

sim <- runSimulation(design=Design, replications=100000, 
                     generate=Generate, analyse=Analyse,
                     summarise=Summarise, store_results=TRUE)
sim

# compute beta/alpha ratio given different alpha
compromise <- function(alpha, sim, Design){
    Design$alpha <- alpha
    out <- reSummarise(Summarise, results=sim, Design=Design)    
    out$q
}

compromise(.3, sim=sim, Design=Design)
compromise(.01, sim=sim, Design=Design)

compromise_root <- function(alpha, target.q, ...)
    compromise(alpha, ...) - target.q


# equal beta/alpha trade-off  
root1 <- uniroot(compromise_root, c(.01, .3), target.q=1, 
        sim=sim, Design=Design)
root1

# beta/alpha trade-off 4 times worse (beta = 4 * alpha)
root4 <- uniroot(compromise_root, c(.01, .3), target.q=4, 
        sim=sim, Design=Design)
root4
```

Hence, based on the empirical $\hat{\alpha}$ and $\hat{\beta}$ estimates, when equal $\beta$ and $\alpha$ errors are desirable then the $\alpha$ to utilize is `r round(root1$root, 3)`, while if the Type I errors are 4 times more costly than the Type II errors then $\alpha$ should be selected to be approximately `r round(root4$root, 3)`.
